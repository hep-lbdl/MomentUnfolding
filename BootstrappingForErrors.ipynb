{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19a34e4-d1be-47cb-be66-b17299ff6dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:55:03.213710: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 14:55:04.616013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e4ba685-9c5b-4739-a754-7f8c532e0d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalize = True\n",
    "N = 10**5\n",
    "n_moments = 2\n",
    "mylambda = []\n",
    "n_bootstraps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc0a1089-fb34-49db-a4f3-b7dc636d0cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moment = 2\n",
    "obs = 'm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be5c6730-ba4a-4c77-b3b5-d466902eef38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load and normalize the data\n",
    "data = np.load('../InfiniteUnfolding/rawdata.npz')\n",
    "substructure_variables = ['pT', 'w', 'q', 'm', 'r', 'tau1s', 'tau2s']\n",
    "data_streams = ['_true', '_true_alt', '_reco', '_reco_alt']\n",
    "n_variables = len(substructure_variables)\n",
    "\n",
    "\n",
    "normalize = False\n",
    "    \n",
    "for var_name in data.files:\n",
    "    globals()[var_name] = data[var_name]\n",
    "    \n",
    "if normalize:\n",
    "    for var_name in substructure_variables:\n",
    "        mu = np.mean(globals()[var_name+data_streams[0]])\n",
    "        sig = np.std(globals()[var_name + data_streams[0]])\n",
    "        for stream in data_streams:\n",
    "            globals()[var_name+stream] = (globals()[var_name+stream] - mu)/sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5116f2-8781-458b-88f5-440b4fff7c61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a366fa-3354-40d1-bb7a-37ac48de27e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebfeb43a-da82-4a24-8b13-ae860e6316ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x_true = rng.normal(0,1, N)\n",
    "# x_reco = rng.normal(x_true, 0.5)\n",
    "# x_true_alt = rng.normal(-0.5,1,N)\n",
    "# x_reco_alt = rng.normal(x_true_alt, 0.5)\n",
    "\n",
    "x_true = q_true\n",
    "x_reco = q_reco\n",
    "x_true_alt = q_true_alt\n",
    "x_reco_alt = q_reco_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "132780d2-c3c0-4b65-bbd1-9bb245771369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xvals = np.concatenate([x_true_alt,x_true])\n",
    "xvals_reco = np.concatenate([x_reco_alt,x_reco])\n",
    "yvals = np.concatenate([np.ones(len(x_true_alt)),np.zeros(len(x_true))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c996d0c-f97b-461c-9346-7c771369bf87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.RandomUniform(minval=-.5, maxval=.5)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, myc, **kwargs):\n",
    "        self.myinit = myc\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._l = self.add_weight(name='l', \n",
    "                                    shape=(n_moments,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit), \n",
    "                                    trainable=True)\n",
    "        \n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.exp(sum([self._l[i]* x**(i+1) for i in range(n_moments)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2a73eb0-460a-474b-a578-a1decba76ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred)/weights_1 +\n",
    "                         (1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "def weighted_binary_crossentropy_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    #tf.print(\"weights\",weights_0,weights_1)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2d7c421-68f2-4f01-a3da-c92887d2d214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for btsrp in range(n_bootstraps):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cb72565-59eb-4b0e-8440-7a0578fe906f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "initializer = tf.keras.initializers.RandomUniform(minval=-5., maxval=5.)\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, myc, **kwargs):\n",
    "        self.myinit = myc\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._lambda0 = self.add_weight(name='lambda0', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit), \n",
    "                                    trainable=True)\n",
    "        self._lambda1 = self.add_weight(name='lambda1', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.Constant(self.myinit), \n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        #return tf.exp(self._lambda1 * x + self._lambda0)\n",
    "        return tf.exp(self._lambda0 * x + self._lambda1 * x**2)\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "    \n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred)/weights_1 +\n",
    "                         (1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "    \n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "    \n",
    "    #tf.print(\"weights\",weights_0,weights_1)\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3902e915-2b01-48d5-bc11-91e85853addc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btstrp = 0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "on epoch= 0 [[0.18000662]] [[0.18000638]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "on epoch= 1 [[0.18000817]] [[0.18000636]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 2 [[0.18001086]] [[0.18000472]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 3 [[0.1800142]] [[0.18000305]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 4 [[0.18001789]] [[0.1800012]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 5 [[0.1800223]] [[0.17999944]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 6 [[0.18002737]] [[0.17999777]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 7 [[0.18003291]] [[0.17999586]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 8 [[0.18003792]] [[0.17999429]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 9 [[0.18004304]] [[0.17999256]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 10 [[0.18004835]] [[0.17999077]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 11 [[0.18005377]] [[0.17998895]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 12 [[0.18005896]] [[0.17998722]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 13 [[0.18006402]] [[0.17998555]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 14 [[0.18006974]] [[0.17998382]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 15 [[0.18007624]] [[0.179982]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 16 [[0.1800831]] [[0.17998025]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 17 [[0.18009007]] [[0.17997849]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 18 [[0.1800968]] [[0.17997691]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 19 [[0.18010396]] [[0.17997506]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 20 [[0.18011105]] [[0.17997324]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 21 [[0.18011779]] [[0.1799716]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 22 [[0.18012488]] [[0.17996973]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 23 [[0.18013173]] [[0.17996785]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 24 [[0.18013895]] [[0.17996562]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 25 [[0.1801458]] [[0.17996326]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 26 [[0.18015283]] [[0.17996058]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 27 [[0.18015975]] [[0.17995787]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 28 [[0.18016678]] [[0.17995498]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 29 [[0.18017364]] [[0.17995214]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 30 [[0.18018073]] [[0.17994913]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 31 [[0.1801877]] [[0.17994618]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 32 [[0.18019444]] [[0.1799433]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 33 [[0.18020159]] [[0.17994016]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 34 [[0.18020874]] [[0.17993703]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 35 [[0.18021566]] [[0.17993397]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 36 [[0.18022233]] [[0.17993104]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "on epoch= 37 [[0.18022954]] [[0.17992777]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 38 [[0.18023652]] [[0.17992464]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 39 [[0.18024337]] [[0.17992151]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 40 [[0.1802504]] [[0.17991829]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 41 [[0.18025744]] [[0.17991507]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 42 [[0.18026447]] [[0.17991179]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 43 [[0.18027139]] [[0.17990854]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 44 [[0.18027836]] [[0.1799053]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 45 [[0.18028522]] [[0.17990208]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 46 [[0.18029207]] [[0.17989889]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 47 [[0.18029928]] [[0.17989546]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "on epoch= 48 [[0.18030638]] [[0.1798921]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "on epoch= 49 [[0.18031329]] [[0.17988884]]\n"
     ]
    }
   ],
   "source": [
    "mylambda = []\n",
    "for btstrp in range(1\n",
    "                    #n_bootstraps\n",
    "                   ):\n",
    "    print(f\"{btstrp = }\")\n",
    "    myc = rng.normal(0, 1)\n",
    "    mymodel_inputtest = Input(shape=(1,))\n",
    "    mymodel_test = MyLayer(myc)(mymodel_inputtest)\n",
    "    model_generator = Model(mymodel_inputtest, mymodel_test)\n",
    "    \n",
    "    inputs_disc = Input((1, ))\n",
    "    hidden_layer_1_disc = Dense(50, activation='relu')(inputs_disc)\n",
    "    hidden_layer_2_disc = Dense(50, activation='relu')(hidden_layer_1_disc)\n",
    "    hidden_layer_3_disc = Dense(50, activation='relu')(hidden_layer_2_disc)\n",
    "    outputs_disc = Dense(1, activation='sigmoid')(hidden_layer_3_disc)\n",
    "    model_discrimantor = Model(inputs=inputs_disc, outputs=outputs_disc)\n",
    "    model_discrimantor.compile(loss=weighted_binary_crossentropy, optimizer='adam')\n",
    "\n",
    "    model_discrimantor.trainable = False\n",
    "    mymodel_gan = Input(shape=(1,))\n",
    "    gan_model = Model(inputs=mymodel_gan,outputs=concatenate([model_discrimantor(mymodel_gan),model_generator(mymodel_gan)]))\n",
    "\n",
    "    gan_model.compile(loss=weighted_binary_crossentropy_GAN, optimizer='adam')\n",
    "    \n",
    "    xvals_1 = np.concatenate([x_true_alt,x_true])\n",
    "    yvals_1 = np.concatenate([np.ones(len(x_true_alt)),np.zeros(len(x_true))])\n",
    "    \n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(xvals_1, yvals_1)\n",
    "    \n",
    "    n_epochs = 50\n",
    "    n_batch = 128*100\n",
    "    n_batches = len(X_train_1) // n_batch\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        lambdasum = np.log(model_generator.predict(np.array([1.])))\n",
    "        lambdasum2 = np.log(model_generator.predict(np.array([2.])))\n",
    "        mylambda1 = (lambdasum2-2*lambdasum)/2\n",
    "        mylambda0 = lambdasum - mylambda1\n",
    "        print(\"on epoch=\",i,mylambda0,mylambda1)\n",
    "        #print(\"  \",np.sum(model_generator.predict(X_train_1,batch_size=1000)))\n",
    "        for j in range(n_batches):\n",
    "            X_batch = X_train_1[j*n_batch:(j+1)*n_batch]\n",
    "            Y_batch = Y_train_1[j*n_batch:(j+1)*n_batch]\n",
    "            W_batch = model_generator(X_batch)\n",
    "            W_batch = np.array(W_batch).flatten()\n",
    "            W_batch[Y_batch==1] = 1\n",
    "            #W_batch[Y_batch==0] = 1\n",
    "            \n",
    "            Y_batch_2 = np.stack((Y_batch, W_batch), axis=1)\n",
    "            \n",
    "            model_discrimantor.train_on_batch(X_batch, Y_batch_2)\n",
    "            \n",
    "            #print(\"      \",j,np.sum(model_generator.predict(X_batch,batch_size=1000)),np.log(model_generator.predict([1.]))-np.log(model_generator.predict([0.])),np.log(model_generator.predict([0.])))\n",
    "            \n",
    "            gan_model.train_on_batch(X_batch[Y_batch==0],np.zeros(len(X_batch[Y_batch==0])))\n",
    "    mylambda += [mylambda0[0, 0], mylambda1[0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae90637e-7980-491f-9ba7-588d63fcae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.reshape(mylambda, (len(mylambda)//2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cba80985-eae3-4432-9b9f-add348fc7813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(lambdas, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc1028-069c-4c6e-a727-09a0ea098282",
   "metadata": {},
   "source": [
    "## Truth and Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5f06ad7-53ee-4efe-a330-f409c10626ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstraps = 100\n",
    "for var in substructure_variables:\n",
    "    for stream in ['_true', '_true_alt']:\n",
    "        globals()[f'bootstrapped_{var}{stream}'] = rng.choice(globals()[var + stream], \n",
    "                                                              replace = True,\n",
    "                                                              size = (N, n_bootstraps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9759a90-0635-47ac-8756-ae6d70f3541e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bootstrapped_w_true, axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4275ae6a-4f1a-4156-8d2f-b496f645c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bold(type): sys.stdout.write(\"\\033[1m\" + type + \"\\033[0m \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6bd0b6e-087c-41ea-8e4b-abd454bf3fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpT_true\u001b[0m \n",
      "E(var^1) error =  0.2950905528869407\n",
      "E(var^2) error =  220.3026561474027\n",
      "\u001b[1mpT_true_alt\u001b[0m \n",
      "E(var^1) error =  0.29130622114907967\n",
      "E(var^2) error =  204.54475261585955\n",
      "\u001b[1mw_true\u001b[0m \n",
      "E(var^1) error =  0.0002577255459616071\n",
      "E(var^2) error =  0.0001134367122041186\n",
      "\u001b[1mw_true_alt\u001b[0m \n",
      "E(var^1) error =  0.00029918196024106996\n",
      "E(var^2) error =  0.00012834982830220426\n",
      "\u001b[1mq_true\u001b[0m \n",
      "E(var^1) error =  0.00037477005907097204\n",
      "E(var^2) error =  8.213229241278366e-05\n",
      "\u001b[1mq_true_alt\u001b[0m \n",
      "E(var^1) error =  0.0003801314767742829\n",
      "E(var^2) error =  7.362636137695333e-05\n",
      "\u001b[1mm_true\u001b[0m \n",
      "E(var^1) error =  0.03035685487560021\n",
      "E(var^2) error =  2.220650073243317\n",
      "\u001b[1mm_true_alt\u001b[0m \n",
      "E(var^1) error =  0.043236974888872175\n",
      "E(var^2) error =  3.049982190476556\n",
      "\u001b[1mr_true\u001b[0m \n",
      "E(var^1) error =  0.0006965746676179559\n",
      "E(var^2) error =  0.0008266905751036265\n",
      "\u001b[1mr_true_alt\u001b[0m \n",
      "E(var^1) error =  0.0006344223936822807\n",
      "E(var^2) error =  0.0007389082948154491\n",
      "\u001b[1mtau1s_true\u001b[0m \n",
      "E(var^1) error =  0.00027520087559086947\n",
      "E(var^2) error =  0.00011570232458948676\n",
      "\u001b[1mtau1s_true_alt\u001b[0m \n",
      "E(var^1) error =  0.00039651856713984783\n",
      "E(var^2) error =  0.00017317366963429313\n",
      "\u001b[1mtau2s_true\u001b[0m \n",
      "E(var^1) error =  0.00016051443624430498\n",
      "E(var^2) error =  3.757106019736525e-05\n",
      "\u001b[1mtau2s_true_alt\u001b[0m \n",
      "E(var^1) error =  0.00017732976834625223\n",
      "E(var^2) error =  4.737475073519267e-05\n"
     ]
    }
   ],
   "source": [
    "for var in substructure_variables:\n",
    "    for stream in ['_true', '_true_alt']:\n",
    "        bold(var + stream)\n",
    "        for moment in [1, 2]:\n",
    "            print(f\"E(var^{moment}) error = \", np.std(np.mean(globals()[f'bootstrapped_{var}{stream}']**moment, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6e23f-9cbc-4fdc-a11a-677f8ee01311",
   "metadata": {},
   "source": [
    "# W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7077721-cdc8-4a37-9c6c-c5cde20b3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaa = 2.2631578947368416\n",
    "lambdab = 4.157894736842105\n",
    "widtha =  0.0430505\n",
    "widthb =  0.0431201\n",
    "x_true = w_true\n",
    "x_true_alt = w_true_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "446690d2-f8ce-4458-9d76-5c1209a48df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.137831846246943e-06\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91d01814-22a2-44a0-aa4f-3c2e1db5133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002900004551257822"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.0029**2 + 5.137831846246943e-06**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff16ab96-d03e-44bb-8ad9-6e343f4cbb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4362108506717495e-06\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt**2, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt**2, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "525423aa-02cb-4614-800e-6c4e5a250eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001280002318405443"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.00128**2 + 2.4362108506717495e-06**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db608376-6b53-426a-843e-550466f29053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab817320-94b0-4915-9316-539938215cb2",
   "metadata": {},
   "source": [
    "# Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9f6827e6-7342-4cb4-b77f-66f1a096d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaa = -0.6122449\n",
    "lambdab = -4.69387755\n",
    "widtha =  0.18031329\n",
    "widthb =  0.17988884\n",
    "x_true = q_true\n",
    "x_true_alt = q_true_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b259d408-a145-4787-a7a6-b472f29019c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.173522915288137e-06\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "44211356-0670-4965-ad1b-b1a878781ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.83505585272889e-05"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.000038**2 + 5.173522915288137e-06**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c39f3ea4-18d3-4ca5-a665-7e0295450e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2719198881974703e-07\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt**2, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt**2, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7dd7fb-6e99-42ab-a417-a3b2c709169b",
   "metadata": {},
   "source": [
    "# M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e57dea04-1985-484c-a30b-e0a9d0f5f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaa = 0.09230769\n",
    "lambdab = 0.006\n",
    "widtha =   0.005\n",
    "widthb =  0.001\n",
    "x_true = m_true\n",
    "x_true_alt = m_true_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21eaede1-2a70-4db0-a3f0-484d679594e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017848425302261717\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3bd57489-2045-487d-a8c6-cf5c5b6210fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46557129269000425"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.17848425302261717**2 + 0.43**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1467a82d-cea6-4a65-a537-b8bde9debf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.016655174143807\n"
     ]
    }
   ],
   "source": [
    "lambda0down = lambdaa - widtha\n",
    "lambda1down = lambdab - widthb\n",
    "weights_down = np.exp(lambda1down*x_true**2+lambda0down*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1down*x_true**2+lambda0down*x_true))\n",
    "down = np.average(x_true_alt**2, weights = weights_down)\n",
    "lambda0up = lambdaa + widtha\n",
    "lambda1up = lambdab + widthb\n",
    "weights_up = np.exp(lambda1up*x_true**2+lambda0up*x_true)*len(x_true_alt)/np.sum(np.exp(lambda1up*x_true**2+lambda0up*x_true))\n",
    "up = np.average(x_true_alt**2, weights = weights_up)\n",
    "print(np.abs(up - down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b616dd8-39c7-43cc-8bf3-76902eae824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.44665655874812"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(35**2 + 10.16655174143807**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5512d21-7f55-413a-a19b-b765e2b236ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (TF, CUDA)",
   "language": "python",
   "name": "python3122"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
