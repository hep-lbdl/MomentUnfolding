{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83f5ae9-1628-4ccc-9bf9-8228b6158dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "#BatchNormalization, Layer, concatenate\n",
    "from keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import energyflow as ef\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=20)\n",
    "plt.rc('font', family = 'serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8ddbaf-ff63-4255-86ea-508b9af7326f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "#These are the same datasets from the OmniFold paper https://arxiv.org/abs/1911.09107.  More detail at https://energyflow.network/docs/datasets/.\n",
    "#Pythia and Herwig are two generators; one will be treated here as the \"simulation\" and one as \"data\".\n",
    "datasets = {'Pythia26': ef.zjets_delphes.load('Pythia26', num_data=1000000),\n",
    "            'Herwig': ef.zjets_delphes.load('Herwig', num_data=1000000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422a2e31-5180-4847-85c4-073128714dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_true = datasets['Pythia26']['gen_widths']\n",
    "w_reco = datasets['Pythia26']['sim_widths']\n",
    "w_true_alt = datasets['Herwig']['gen_widths']\n",
    "w_reco_alt = datasets['Herwig']['sim_widths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba47dd0-694b-48e0-9f59-31a8d9f4b310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "    \n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred) +\n",
    "                         (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80020fb-68ff-4ea9-a089-6071a65b714c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xvals_1 = np.concatenate([w_true_alt,w_true])\n",
    "yvals_1 = np.concatenate([np.ones(len(w_true_alt)),np.zeros(len(w_true))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c12368-1cda-4606-a351-09bed3049efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 19:59:22.983633: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-21 19:59:25.011983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 77973 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2023-12-21 19:59:25.013644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78373 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2023-12-21 19:59:25.015128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78373 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "2023-12-21 19:59:25.016467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78373 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2023-12-21 19:59:26.008745: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-12-21 19:59:27.025675: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda1 = -2.0, loss = 0.6665012240409851\n",
      "lambda1 = -1.368421052631579, loss = 0.6718755960464478\n",
      "lambda1 = -0.736842105263158, loss = 0.6770674586296082\n",
      "lambda1 = -0.10526315789473695, loss = 0.6814423203468323\n",
      "lambda1 = 0.5263157894736841, loss = 0.6854212284088135\n",
      "lambda1 = 1.1578947368421053, loss = 0.6882736682891846\n",
      "lambda1 = 1.789473684210526, loss = 0.6899831891059875\n",
      "lambda1 = 2.421052631578947, loss = 0.6906856894493103\n",
      "lambda1 = 3.052631578947368, loss = 0.6902337670326233\n",
      "lambda1 = 3.6842105263157894, loss = 0.6878787875175476\n",
      "lambda1 = 4.315789473684211, loss = 0.6840240359306335\n",
      "lambda1 = 4.947368421052631, loss = 0.6781253814697266\n",
      "lambda1 = 5.578947368421052, loss = 0.6701961755752563\n",
      "lambda1 = 6.210526315789473, loss = 0.6605696678161621\n",
      "lambda1 = 6.842105263157894, loss = 0.6483500599861145\n",
      "lambda1 = 7.473684210526315, loss = 0.6339715719223022\n",
      "lambda1 = 8.105263157894736, loss = 0.6176109910011292\n",
      "lambda1 = 8.736842105263158, loss = 0.5994991064071655\n",
      "lambda1 = 9.368421052631579, loss = 0.5793387293815613\n",
      "lambda1 = 10.0, loss = 0.5579418540000916\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "\n",
    "losses_width = []\n",
    "for lambda1 in np.linspace(-2,10,20):\n",
    "\n",
    "    weights_1 = np.concatenate([np.ones(len(w_true_alt)),np.exp(lambda1*w_true)*len(w_true_alt)/np.sum(np.exp(lambda1*w_true))])\n",
    "\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1, w_train_1, w_test_1 = train_test_split(xvals_1, yvals_1, weights_1)\n",
    "\n",
    "    Y_train_2 = np.stack((Y_train_1, w_train_1), axis=1)\n",
    "    Y_test_2 = np.stack((Y_test_1, w_test_1), axis=1)\n",
    "\n",
    "    inputs = Input((1, ))\n",
    "    hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "    hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "    hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "    outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(loss=weighted_binary_crossentropy, optimizer='Adam', metrics=['accuracy'])\n",
    "    model.fit(X_train_1,\n",
    "              Y_train_2,\n",
    "              epochs=3,\n",
    "              batch_size=1000,\n",
    "              verbose=0)\n",
    "\n",
    "    losses_width+=[model.history.history['loss'][-1]]\n",
    "    print(f\"{lambda1 = }, loss = {losses_width[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2fb3009-32a6-4a3f-8629-79328cd7695e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda2 = -2.0, loss = 0.6771501898765564\n",
      "lambda2 = -1.368421052631579, loss = 0.6787495017051697\n",
      "lambda2 = -0.736842105263158, loss = 0.6804331541061401\n",
      "lambda2 = -0.10526315789473695, loss = 0.6818827986717224\n",
      "lambda2 = 0.5263157894736841, loss = 0.683295726776123\n",
      "lambda2 = 1.1578947368421053, loss = 0.6845768094062805\n",
      "lambda2 = 1.789473684210526, loss = 0.6856462955474854\n",
      "lambda2 = 2.421052631578947, loss = 0.686540424823761\n",
      "lambda2 = 3.052631578947368, loss = 0.687204897403717\n",
      "lambda2 = 3.6842105263157894, loss = 0.6875933408737183\n",
      "lambda2 = 4.315789473684211, loss = 0.6878448128700256\n",
      "lambda2 = 4.947368421052631, loss = 0.6876720786094666\n",
      "lambda2 = 5.578947368421052, loss = 0.6873108148574829\n",
      "lambda2 = 6.210526315789473, loss = 0.6863394379615784\n",
      "lambda2 = 6.842105263157894, loss = 0.685082197189331\n",
      "lambda2 = 7.473684210526315, loss = 0.683343231678009\n",
      "lambda2 = 8.105263157894736, loss = 0.6809446811676025\n",
      "lambda2 = 8.736842105263158, loss = 0.6781526803970337\n",
      "lambda2 = 9.368421052631579, loss = 0.6747816801071167\n",
      "lambda2 = 10.0, loss = 0.6708036065101624\n"
     ]
    }
   ],
   "source": [
    "#second moment\n",
    "\n",
    "losses_width2 = []\n",
    "for lambda2 in np.linspace(-2,10,20):\n",
    "    \n",
    "    weights_1 = np.concatenate([np.ones(len(w_true_alt)),np.exp(lambda2*w_true**2)*len(w_true_alt)/np.sum(np.exp(lambda2*w_true**2))])\n",
    "\n",
    "    X_train_1, X_test_1, Y_train_1, Y_test_1, w_train_1, w_test_1 = train_test_split(xvals_1, yvals_1, weights_1)\n",
    "\n",
    "    Y_train_2 = np.stack((Y_train_1, w_train_1), axis=1)\n",
    "    Y_test_2 = np.stack((Y_test_1, w_test_1), axis=1)\n",
    "\n",
    "    inputs = Input((1, ))\n",
    "    hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "    hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "    hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "    outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(loss=weighted_binary_crossentropy, optimizer='Adam', metrics=['accuracy'])\n",
    "    model.fit(X_train_1,\n",
    "              Y_train_2,\n",
    "              epochs=3,\n",
    "              batch_size=1000,\n",
    "              verbose=0)\n",
    "    losses_width2+=[model.history.history['loss'][-1]]\n",
    "    print(f\"{lambda2 = }, loss = {losses_width2[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2262e4ad-9990-47e4-8c74-c47882cd875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 2.421052631578947\n",
    "lambda2 = 4.315789473684211\n",
    "xvals = np.concatenate([w_true_alt,w_true])\n",
    "yvals = np.concatenate([np.ones(len(w_true_alt)),np.zeros(len(w_true))])\n",
    "weights = np.concatenate([np.ones(len(w_true_alt)),np.exp(lambda1*w_true + lambda2*w_true**2)*len(w_true_alt)/np.sum(np.exp(lambda1*w_true + lambda2*w_true**2))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdecb2f9-a3b7-4b41-b9b8-35301d84e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('npfiles/jetlosses', xvals = xvals, yvals = yvals, weights = weights,\n",
    "         losses1 = losses_width, losses2 = losses_width2,\n",
    "         lambda1 = [lambda1], lambda2 = [lambda2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161aaa0-815d-4879-b43a-a5ff8e2a0593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a38c0-a4b2-4d13-aee8-dd5dd26c76b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561451a-c607-4328-9c33-bd2330f5b77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.6.0",
   "language": "python",
   "name": "tensorflow-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
