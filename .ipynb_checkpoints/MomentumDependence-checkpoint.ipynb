{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import energyflow as ef\n",
    "import energyflow.archs\n",
    "from energyflow.archs import PFN\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # pick a number < 4 on ML4HEP\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "#These are the same datasets from the OmniFold paper https://arxiv.org/abs/1911.09107.  More detail at https://energyflow.network/docs/datasets/.\n",
    "#Pythia and Herwig are two generators; one will be treated here as the \"simulation\" and one as \"data\".\n",
    "datasets = {'Pythia26': ef.zjets_delphes.load('Pythia26', num_data=1000000),\n",
    "            'Herwig': ef.zjets_delphes.load('Herwig', num_data=1000000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gen = datasets['Pythia26']['gen_widths'] #gen = particle level\n",
    "w_sim = datasets['Pythia26']['sim_widths'] #sim = detector level\n",
    "w_truth = datasets['Herwig']['gen_widths']\n",
    "w_data = datasets['Herwig']['sim_widths']\n",
    "\n",
    "p_gen = datasets['Pythia26']['gen_jets'][:,0] #gen = particle level\n",
    "p_sim = datasets['Pythia26']['sim_jets'][:,0] #sim = detector level\n",
    "p_truth = datasets['Herwig']['gen_jets'][:,0]\n",
    "p_data = datasets['Herwig']['sim_jets'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred)/weights_1 +\n",
    "                         (1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "def weighted_binary_crossentropy_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    #tf.print(\"weights\",weights_0,weights_1)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_28'), name='input_28', description=\"created by layer 'input_28'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer dense_106 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m model_discrimantor\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m mymodel_gan \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m---> 32\u001b[0m gan_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmymodel_gan,outputs\u001b[38;5;241m=\u001b[39mconcatenate([\u001b[43mmodel_discrimantor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmymodel_gan\u001b[49m\u001b[43m)\u001b[49m,model_generator(mymodel_gan)]))\n\u001b[1;32m     34\u001b[0m gan_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mweighted_binary_crossentropy_GAN, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:888\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m    887\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    892\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:414\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:550\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    547\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 550\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/base_layer.py:1020\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m eager \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1015\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1016\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m   1017\u001b[0m     build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m eager,\n\u001b[1;32m   1018\u001b[0m     training\u001b[38;5;241m=\u001b[39mtraining_mode):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[43minput_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_input_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m eager:\n\u001b[1;32m   1022\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m       value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {value, \u001b[38;5;28;01mNone\u001b[39;00m}:\n\u001b[0;32m--> 250\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m incompatible with the layer: expected axis \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(axis) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    253\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of input shape to have value \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(value) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    254\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but received input with shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m display_shape(x\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer dense_106 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 1)"
     ]
    }
   ],
   "source": [
    "xvals_1 = np.concatenate([w_truth,w_gen])\n",
    "pvals_1 = np.concatenate([p_truth, p_gen])\n",
    "yvals_1 = np.concatenate([np.ones(len(w_truth)),np.zeros(len(w_gen))])\n",
    "\n",
    "xvals_2 = np.concatenate([w_data,w_sim])\n",
    "pvals_2 = np.concatenate([p_data, p_sim])\n",
    "yvals_2 = np.concatenate([np.ones(len(w_data)),np.zeros(len(w_sim))])\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1, X_train_2, X_test_2, Y_train_2, Y_test_2 , P_train_1, P_test_1, P_train_2, P_train_1 = train_test_split(xvals_1, yvals_1, xvals_2, yvals_2, pvals_1, pvals_2)\n",
    "\n",
    "\n",
    "inputs_gen = Input(shape=(2,))\n",
    "hidden_layer_1_gen = Dense(50, activation='relu')(inputs_gen)\n",
    "hidden_layer_2_gen = Dense(50, activation='relu')(hidden_layer_1_gen)\n",
    "hidden_layer_3_gen = Dense(50, activation='relu')(hidden_layer_2_gen)\n",
    "outputs_gen = tf.exp(Dense(1, activation='linear')(hidden_layer_3_gen))\n",
    "model_generator = Model(inputs=inputs_gen, outputs=outputs_gen)\n",
    "\n",
    "\n",
    "\n",
    "inputs_disc = Input((2, ))\n",
    "hidden_layer_1_disc = Dense(50, activation='relu')(inputs_disc)\n",
    "hidden_layer_2_disc = Dense(50, activation='relu')(hidden_layer_1_disc)\n",
    "hidden_layer_3_disc = Dense(50, activation='relu')(hidden_layer_2_disc)\n",
    "outputs_disc = Dense(1, activation='sigmoid')(hidden_layer_3_disc)\n",
    "model_discrimantor = Model(inputs=inputs_disc, outputs=outputs_disc)\n",
    "\n",
    "model_discrimantor.compile(loss=weighted_binary_crossentropy, optimizer='adam')\n",
    "\n",
    "model_discrimantor.trainable = False\n",
    "mymodel_gan = Input(shape=(1,))\n",
    "gan_model = Model(inputs=mymodel_gan,outputs=concatenate([model_discrimantor(mymodel_gan),model_generator(mymodel_gan)]))\n",
    "\n",
    "gan_model.compile(loss=weighted_binary_crossentropy_GAN, optimizer='adam')\n",
    "\n",
    "n_epochs = 20\n",
    "n_batch = 128*10\n",
    "n_batches = len(X_train_1) // n_batch\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    #print(\"  \",np.sum(model_generator.predict(X_train_1,batch_size=1000)))\n",
    "    print(i)\n",
    "    for j in range(n_batches):\n",
    "        X_batch = X_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        Y_batch = Y_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        P_batch = P_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        \n",
    "#         print(f\"{X_batch.shape = }\")\n",
    "#         print(f\"{P_batch.shape = }\")\n",
    "        \n",
    "    \n",
    "        XP_stack = np.stack((X_batch, P_batch), axis=1)\n",
    "        W_batch = model_generator(XP_stack)\n",
    "        W_batch = np.array(W_batch).flatten()\n",
    "        W_batch[Y_batch==1] = 1\n",
    "        #W_batch[Y_batch==0] = 1\n",
    "        \n",
    "        Y_batch_2 = np.stack((Y_batch, W_batch), axis=1)\n",
    "        \n",
    "        model_discrimantor.train_on_batch(XP_stack, Y_batch_2)\n",
    "        \n",
    "        #print(\"      \",j,np.sum(model_generator.predict(X_batch,batch_size=1000)),np.log(model_generator.predict([1.]))-np.log(model_generator.predict([0.])),np.log(model_generator.predict([0.])))\n",
    "        \n",
    "        gan_model.train_on_batch(X_batch[Y_batch==0],np.zeros(len(X_batch[Y_batch==0])))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
