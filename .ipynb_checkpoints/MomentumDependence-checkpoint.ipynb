{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import energyflow as ef\n",
    "import energyflow.archs\n",
    "from energyflow.archs import PFN\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # pick a number < 4 on ML4HEP\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "#These are the same datasets from the OmniFold paper https://arxiv.org/abs/1911.09107.  More detail at https://energyflow.network/docs/datasets/.\n",
    "#Pythia and Herwig are two generators; one will be treated here as the \"simulation\" and one as \"data\".\n",
    "datasets = {'Pythia26': ef.zjets_delphes.load('Pythia26', num_data=1000000),\n",
    "            'Herwig': ef.zjets_delphes.load('Herwig', num_data=1000000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gen = datasets['Pythia26']['gen_widths'] #gen = particle level\n",
    "w_sim = datasets['Pythia26']['sim_widths'] #sim = detector level\n",
    "w_truth = datasets['Herwig']['gen_widths']\n",
    "w_data = datasets['Herwig']['sim_widths']\n",
    "\n",
    "p_gen = datasets['Pythia26']['gen_jets'][:,0] #gen = particle level\n",
    "p_sim = datasets['Pythia26']['sim_jets'][:,0] #sim = detector level\n",
    "p_truth = datasets['Herwig']['gen_jets'][:,0]\n",
    "p_data = datasets['Herwig']['sim_jets'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.gather(y_true, [1], axis=1) # event weights\n",
    "    y_true = tf.gather(y_true, [0], axis=1) # actual y_true for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = -weights * ((y_true) * K.log(y_pred)/weights_1 +\n",
    "                         (1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)\n",
    "\n",
    "def weighted_binary_crossentropy_GAN(y_true, y_pred):\n",
    "    weights = tf.gather(y_pred, [1], axis=1) # event weights\n",
    "    y_pred = tf.gather(y_pred, [0], axis=1) # actual y_pred for loss\n",
    "\n",
    "    weights_1 = K.sum(y_true*weights)\n",
    "    weights_0 = K.sum((1-y_true)*weights)\n",
    "\n",
    "    #tf.print(\"weights\",weights_0,weights_1)\n",
    "\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    t_loss = weights * ((1 - y_true) * K.log(1 - y_pred)/weights_0)\n",
    "    return K.mean(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"dense_10\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m hidden_layer_3_gen \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m50\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(hidden_layer_2_gen)\n\u001b[1;32m     16\u001b[0m outputs_gen \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexp(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)(hidden_layer_3_gen))\n\u001b[0;32m---> 17\u001b[0m model_generator \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m inputs_disc \u001b[38;5;241m=\u001b[39m Input((\u001b[38;5;241m2\u001b[39m, ))\n\u001b[1;32m     22\u001b[0m hidden_layer_1_disc \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m50\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(inputs_disc)\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:109\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m generic_utils\u001b[38;5;241m.\u001b[39mvalidate_kwargs(kwargs, {})\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28msuper\u001b[39m(Functional, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname, trainable\u001b[38;5;241m=\u001b[39mtrainable)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/clusterfs/ml4hep_nvme2/bpnachman/anaconda3/envs/ml4hep2/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:192\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_map_graph_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/functional.py:979\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraph disconnected: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    980\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot obtain value for tensor \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    981\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    982\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe following previous layers \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    983\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwere accessed without issue: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    984\u001b[0m                      \u001b[38;5;28mstr\u001b[39m(layers_with_complete_input))\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m    986\u001b[0m   computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"dense_10\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "xvals_1 = np.concatenate([w_truth,w_gen])\n",
    "pvals_1 = np.concatenate([p_truth, p_gen])\n",
    "yvals_1 = np.concatenate([np.ones(len(w_truth)),np.zeros(len(w_gen))])\n",
    "\n",
    "xvals_2 = np.concatenate([w_data,w_sim])\n",
    "pvals_2 = np.concatenate([p_data, p_sim])\n",
    "yvals_2 = np.concatenate([np.ones(len(w_data)),np.zeros(len(w_sim))])\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1, X_train_2, X_test_2, Y_train_2, Y_test_2 , P_train_1, P_test_1, P_train_2, P_train_1 = train_test_split(xvals_1, yvals_1, xvals_2, yvals_2, pvals_1, pvals_2)\n",
    "\n",
    "\n",
    "inputs_gen = Input(shape=(2,))\n",
    "hidden_layer_1_gen = Dense(50, activation='relu')(mymodel_inputtest)\n",
    "hidden_layer_2_gen = Dense(50, activation='relu')(hidden_layer_1_gen)\n",
    "hidden_layer_3_gen = Dense(50, activation='relu')(hidden_layer_2_gen)\n",
    "outputs_gen = tf.exp(Dense(1, activation='linear')(hidden_layer_3_gen))\n",
    "model_generator = Model(inputs=inputs_gen, outputs=outputs_gen)\n",
    "\n",
    "\n",
    "\n",
    "inputs_disc = Input((2, ))\n",
    "hidden_layer_1_disc = Dense(50, activation='relu')(inputs_disc)\n",
    "hidden_layer_2_disc = Dense(50, activation='relu')(hidden_layer_1_disc)\n",
    "hidden_layer_3_disc = Dense(50, activation='relu')(hidden_layer_2_disc)\n",
    "outputs_disc = Dense(1, activation='sigmoid')(hidden_layer_3_disc)\n",
    "model_discrimantor = Model(inputs=inputs_disc, outputs=outputs_disc)\n",
    "\n",
    "n_epochs = 20\n",
    "n_batch = 128*10\n",
    "n_batches = len(X_train_1) // n_batch\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    lambdasum = np.log(model_generator.predict([1.]))\n",
    "    lambdasum2 = np.log(model_generator.predict([2.]))\n",
    "    mylambda1 = (lambdasum2-2*lambdasum)/2\n",
    "    mylambda0 = lambdasum - mylambda1\n",
    "    print(\"on epoch=\",i,mylambda0,mylambda1)\n",
    "    #print(\"  \",np.sum(model_generator.predict(X_train_1,batch_size=1000)))\n",
    "    for j in range(n_batches):\n",
    "        X_batch = X_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        Y_batch = Y_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        P_batch = P_train_1[j*n_batch:(j+1)*n_batch]\n",
    "        W_batch = model_generator(X_batch, P_batch)\n",
    "        W_batch = np.array(W_batch).flatten()\n",
    "        W_batch[Y_batch==1] = 1\n",
    "        #W_batch[Y_batch==0] = 1\n",
    "        \n",
    "        Y_batch_2 = np.stack((Y_batch, W_batch), axis=1)\n",
    "        \n",
    "        model_discrimantor.train_on_batch(X_batch, Y_batch_2)\n",
    "        \n",
    "        #print(\"      \",j,np.sum(model_generator.predict(X_batch,batch_size=1000)),np.log(model_generator.predict([1.]))-np.log(model_generator.predict([0.])),np.log(model_generator.predict([0.])))\n",
    "        \n",
    "        gan_model.train_on_batch(X_batch[Y_batch==0],np.zeros(len(X_batch[Y_batch==0])))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
